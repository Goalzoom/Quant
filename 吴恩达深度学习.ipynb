{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# python爬取招聘网站数据，利用tableau可视化交互大屏，指导你如何学习、找工作!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "teminal是指系统的输入命令"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "爬取岗位：大数据、数据分析、机器学习、人工智能等相关岗位；\n",
    "\n",
    "爬取字段：公司名、岗位名、工作地址、薪资、发布时间、工作描述、公司类型、员工人数、所属行业；\n",
    "\n",
    "说明：基于51job招聘网站，我们搜索全国对于“数据”岗位的需求，大概有2000页。我们爬取的字段，既有一级页面的相关信息，还有二级页面的部分信息；\n",
    "\n",
    "爬取思路：先针对某一页数据的一级页面做一个解析，然后再进行二级页面做一个解析，最后再进行翻页操作；\n",
    "\n",
    "使用工具：Python+requests+lxml+pandas+time\n",
    "\n",
    "网站解析方式：Xpath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入相关库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-20T08:50:20.853939Z",
     "start_time": "2020-03-20T08:50:19.548676Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from lxml import etree\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 关于翻页的说明"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-20T08:52:27.668053Z",
     "start_time": "2020-03-20T08:52:27.302799Z"
    }
   },
   "outputs": [],
   "source": [
    "# 第一页的特点\n",
    "https://search.51job.com/list/000000,000000,0000,00,9,99,%25E6%2595%25B0%25E6%258D%25AE,2,1.html?\n",
    "# 第二页的特点\n",
    "https://search.51job.com/list/000000,000000,0000,00,9,99,%25E6%2595%25B0%25E6%258D%25AE,2,2.html?\n",
    "# 第三页的特点\n",
    "https://search.51job.com/list/000000,000000,0000,00,9,99,%25E6%2595%25B0%25E6%258D%25AE,2,3.html?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://search.51job.com/list/000000,000000,0000,00,9,99,%25E6%2595%25B0%25E6%258D%25AE,2,3.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-20T08:45:46.395879Z",
     "start_time": "2020-03-20T08:45:46.381841Z"
    }
   },
   "source": [
    "注意：通过对于页面的观察，可以看出，就一个地方的数字变化了，因此只需要做字符串拼接，然后循环爬取即可。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 完整的爬取代码"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$E=mc^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-20T08:52:35.863Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在爬取第1页的数据\n",
      "正在爬取第2页的数据\n",
      "正在爬取第3页的数据\n",
      "正在爬取第4页的数据\n",
      "正在爬取第5页的数据\n",
      "正在爬取第6页的数据\n",
      "正在爬取第7页的数据\n",
      "正在爬取第8页的数据\n",
      "正在爬取第9页的数据\n",
      "正在爬取第10页的数据\n",
      "正在爬取第11页的数据\n",
      "正在爬取第12页的数据\n",
      "正在爬取第13页的数据\n",
      "正在爬取第14页的数据\n",
      "正在爬取第15页的数据\n",
      "正在爬取第16页的数据\n",
      "正在爬取第17页的数据\n",
      "正在爬取第18页的数据\n",
      "正在爬取第19页的数据\n",
      "正在爬取第20页的数据\n",
      "正在爬取第21页的数据\n",
      "正在爬取第22页的数据\n",
      "正在爬取第23页的数据\n",
      "正在爬取第24页的数据\n",
      "正在爬取第25页的数据\n",
      "正在爬取第26页的数据\n",
      "正在爬取第27页的数据\n",
      "正在爬取第28页的数据\n",
      "正在爬取第29页的数据\n",
      "正在爬取第30页的数据\n",
      "正在爬取第31页的数据\n",
      "正在爬取第32页的数据\n",
      "正在爬取第33页的数据\n",
      "正在爬取第34页的数据\n",
      "正在爬取第35页的数据\n",
      "正在爬取第36页的数据\n",
      "正在爬取第37页的数据\n",
      "正在爬取第38页的数据\n",
      "正在爬取第39页的数据\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from lxml import etree\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "for i in range(1,1501):\n",
    "    print(\"正在爬取第\" + str(i) + \"页的数据\")\n",
    "    url_pre = \"https://search.51job.com/list/000000,000000,0000,00,9,99,%25E6%2595%25B0%25E6%258D%25AE,2,\"\n",
    "    url_end = \".html?\"\n",
    "    url = url_pre + str(i) + url_end\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/73.0.3683.86 Safari/537.36'\n",
    "    }\n",
    "    web = requests.get(url, headers=headers)\n",
    "    web.encoding = \"gbk\"\n",
    "    dom = etree.HTML(web.text)\n",
    "    # 1、岗位名称\n",
    "    job_name = dom.xpath('//div[@class=\"dw_table\"]/div[@class=\"el\"]//p/span/a[@target=\"_blank\"]/@title')\n",
    "    # 2、公司名称\n",
    "    company_name = dom.xpath('//div[@class=\"dw_table\"]/div[@class=\"el\"]/span[@class=\"t2\"]/a[@target=\"_blank\"]/@title')\n",
    "    # 3、工作地点\n",
    "    address = dom.xpath('//div[@class=\"dw_table\"]/div[@class=\"el\"]/span[@class=\"t3\"]/text()')\n",
    "    # 4、工资\n",
    "    salary_mid = dom.xpath('//div[@class=\"dw_table\"]/div[@class=\"el\"]/span[@class=\"t4\"]')\n",
    "    salary = [i.text for i in salary_mid]\n",
    "    # 5、发布日期\n",
    "    release_time = dom.xpath('//div[@class=\"dw_table\"]/div[@class=\"el\"]/span[@class=\"t5\"]/text()')\n",
    "    # 6、获取二级网址url\n",
    "    deep_url = dom.xpath('//div[@class=\"dw_table\"]/div[@class=\"el\"]//p/span/a[@target=\"_blank\"]/@href')\n",
    "    RandomAll = []\n",
    "    JobDescribe = []\n",
    "    CompanyType = []\n",
    "    CompanySize = []\n",
    "    Industry = []\n",
    "    for i in range(len(deep_url)):\n",
    "        web_test = requests.get(deep_url[i], headers=headers)\n",
    "        web_test.encoding = \"gbk\"\n",
    "        dom_test = etree.HTML(web_test.text)\n",
    "        # 7、爬取经验、学历信息，先合在一个字段里面，以后再做数据清洗。命名为random_all\n",
    "        random_all = dom_test.xpath('//div[@class=\"tHeader tHjob\"]//div[@class=\"cn\"]/p[@class=\"msg ltype\"]/text()')\n",
    "        # 8、岗位描述性息\n",
    "        job_describe = dom_test.xpath('//div[@class=\"tBorderTop_box\"]//div[@class=\"bmsg job_msg inbox\"]/p/text()')\n",
    "        # 9、公司类型\n",
    "        company_type = dom_test.xpath('//div[@class=\"tCompany_sidebar\"]//div[@class=\"com_tag\"]/p[1]/@title')\n",
    "        # 10、公司规模(人数)\n",
    "        company_size = dom_test.xpath('//div[@class=\"tCompany_sidebar\"]//div[@class=\"com_tag\"]/p[2]/@title')\n",
    "        # 11、所属行业(公司)\n",
    "        industry = dom_test.xpath('//div[@class=\"tCompany_sidebar\"]//div[@class=\"com_tag\"]/p[3]/@title')\n",
    "        # 将上述信息保存到各自的列表中\n",
    "        RandomAll.append(random_all)\n",
    "        JobDescribe.append(job_describe)\n",
    "        CompanyType.append(company_type)\n",
    "        CompanySize.append(company_size)\n",
    "        Industry.append(industry)\n",
    "        # 为了反爬，设置睡眠时间\n",
    "        time.sleep(1)\n",
    "    # 由于我们需要爬取很多页，为了防止最后一次性保存所有数据出现的错误，因此，我们每获取一夜的数据，就进行一次数据存取。\n",
    "    df = pd.DataFrame()\n",
    "    df[\"岗位名称\"] = job_name\n",
    "    df[\"公司名称\"] = company_name\n",
    "    df[\"工作地点\"] = address\n",
    "    df[\"工资\"] = salary\n",
    "    df[\"发布日期\"] = release_time\n",
    "    df[\"经验、学历\"] = RandomAll\n",
    "    df[\"公司类型\"] = CompanyType\n",
    "    df[\"公司规模\"] = CompanySize\n",
    "    df[\"所属行业\"] = Industry\n",
    "    df[\"岗位描述\"] = JobDescribe\n",
    "    # 这里在写出过程中，有可能会写入失败，为了解决这个问题，我们使用异常处理。\n",
    "    try:\n",
    "        df.to_csv(\"job_info.csv\", mode=\"a+\", header=None, index=None, encoding=\"gbk\")\n",
    "    except:\n",
    "        print(\"当页数据写入失败\")\n",
    "    time.sleep(1)\n",
    "print(\"数据爬取完毕，是不是很开心！！！\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
